digraph {
	graph [size="219.75,219.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140446258330504 [label="
 (50, 4)" fillcolor=darkolivegreen1]
	140446581489224 [label=AddmmBackward0]
	140446581489056 -> 140446581489224
	140446581546184 [label="C_gender.linear.bias
 (4)" fillcolor=lightblue]
	140446581546184 -> 140446581489056
	140446581489056 [label=AccumulateGrad]
	140446581489336 -> 140446581489224
	140446581489336 [label=SliceBackward0]
	140446581489392 -> 140446581489336
	140446581489392 [label=SliceBackward0]
	140446581489504 -> 140446581489392
	140446581489504 [label=ReluBackward0]
	140446581489616 -> 140446581489504
	140446581489616 [label=NativeBatchNormBackward0]
	140446300127072 -> 140446581489616
	140446300127072 [label=AddmmBackward0]
	140446300127016 -> 140446300127072
	140446581545624 [label="encoder.arcFace50.fc.bias
 (2048)" fillcolor=lightblue]
	140446581545624 -> 140446300127016
	140446300127016 [label=AccumulateGrad]
	140446300126960 -> 140446300127072
	140446300126960 [label=ReshapeAliasBackward0]
	140446300126624 -> 140446300126960
	140446300126624 [label=NativeBatchNormBackward0]
	140446300126736 -> 140446300126624
	140446300126736 [label=AddBackward0]
	140446300126456 -> 140446300126736
	140446300126456 [label=NativeBatchNormBackward0]
	140446300126232 -> 140446300126456
	140446300126232 [label=MkldnnConvolutionBackward0]
	140446300126008 -> 140446300126232
	140446300126008 [label=PreluBackward0]
	140446300125784 -> 140446300126008
	140446300125784 [label=NativeBatchNormBackward0]
	140446300125560 -> 140446300125784
	140446300125560 [label=MkldnnConvolutionBackward0]
	140446300125280 -> 140446300125560
	140446300125280 [label=NativeBatchNormBackward0]
	140446300126400 -> 140446300125280
	140446300126400 [label=AddBackward0]
	140446300123488 -> 140446300126400
	140446300123488 [label=NativeBatchNormBackward0]
	140446300123656 -> 140446300123488
	140446300123656 [label=MkldnnConvolutionBackward0]
	140446300123880 -> 140446300123656
	140446300123880 [label=PreluBackward0]
	140446300124048 -> 140446300123880
	140446300124048 [label=NativeBatchNormBackward0]
	140446300124216 -> 140446300124048
	140446300124216 [label=MkldnnConvolutionBackward0]
	140446300124440 -> 140446300124216
	140446300124440 [label=NativeBatchNormBackward0]
	140446300123544 -> 140446300124440
	140446300123544 [label=AddBackward0]
	140446300124776 -> 140446300123544
	140446300124776 [label=NativeBatchNormBackward0]
	140446300124944 -> 140446300124776
	140446300124944 [label=MkldnnConvolutionBackward0]
	140446300125112 -> 140446300124944
	140446300125112 [label=PreluBackward0]
	140446300213376 -> 140446300125112
	140446300213376 [label=NativeBatchNormBackward0]
	140446300213544 -> 140446300213376
	140446300213544 [label=MkldnnConvolutionBackward0]
	140446300213768 -> 140446300213544
	140446300213768 [label=NativeBatchNormBackward0]
	140446300213936 -> 140446300213768
	140446300213936 [label=AddBackward0]
	140446300214160 -> 140446300213936
	140446300214160 [label=NativeBatchNormBackward0]
	140446300214328 -> 140446300214160
	140446300214328 [label=MkldnnConvolutionBackward0]
	140446300214552 -> 140446300214328
	140446300214552 [label=PreluBackward0]
	140446300214720 -> 140446300214552
	140446300214720 [label=NativeBatchNormBackward0]
	140446300214888 -> 140446300214720
	140446300214888 [label=MkldnnConvolutionBackward0]
	140446300215112 -> 140446300214888
	140446300215112 [label=NativeBatchNormBackward0]
	140446300214216 -> 140446300215112
	140446300214216 [label=AddBackward0]
	140446300215448 -> 140446300214216
	140446300215448 [label=NativeBatchNormBackward0]
	140446300215616 -> 140446300215448
	140446300215616 [label=MkldnnConvolutionBackward0]
	140446300215840 -> 140446300215616
	140446300215840 [label=PreluBackward0]
	140446300216008 -> 140446300215840
	140446300216008 [label=NativeBatchNormBackward0]
	140446300216176 -> 140446300216008
	140446300216176 [label=MkldnnConvolutionBackward0]
	140446300216400 -> 140446300216176
	140446300216400 [label=NativeBatchNormBackward0]
	140446300215504 -> 140446300216400
	140446300215504 [label=AddBackward0]
	140446300216736 -> 140446300215504
	140446300216736 [label=NativeBatchNormBackward0]
	140446300216904 -> 140446300216736
	140446300216904 [label=MkldnnConvolutionBackward0]
	140446300217128 -> 140446300216904
	140446300217128 [label=PreluBackward0]
	140446300217296 -> 140446300217128
	140446300217296 [label=NativeBatchNormBackward0]
	140446300217528 -> 140446300217296
	140446300217528 [label=MkldnnConvolutionBackward0]
	140446300217752 -> 140446300217528
	140446300217752 [label=NativeBatchNormBackward0]
	140446300216792 -> 140446300217752
	140446300216792 [label=AddBackward0]
	140446300218088 -> 140446300216792
	140446300218088 [label=NativeBatchNormBackward0]
	140446300218256 -> 140446300218088
	140446300218256 [label=MkldnnConvolutionBackward0]
	140446300218480 -> 140446300218256
	140446300218480 [label=PreluBackward0]
	140446300218648 -> 140446300218480
	140446300218648 [label=NativeBatchNormBackward0]
	140446300218816 -> 140446300218648
	140446300218816 [label=MkldnnConvolutionBackward0]
	140446300219040 -> 140446300218816
	140446300219040 [label=NativeBatchNormBackward0]
	140446300218144 -> 140446300219040
	140446300218144 [label=AddBackward0]
	140446300219376 -> 140446300218144
	140446300219376 [label=NativeBatchNormBackward0]
	140446300219544 -> 140446300219376
	140446300219544 [label=MkldnnConvolutionBackward0]
	140446300219768 -> 140446300219544
	140446300219768 [label=PreluBackward0]
	140446300219936 -> 140446300219768
	140446300219936 [label=NativeBatchNormBackward0]
	140446300220104 -> 140446300219936
	140446300220104 [label=MkldnnConvolutionBackward0]
	140446300220328 -> 140446300220104
	140446300220328 [label=NativeBatchNormBackward0]
	140446300219432 -> 140446300220328
	140446300219432 [label=AddBackward0]
	140446300220664 -> 140446300219432
	140446300220664 [label=NativeBatchNormBackward0]
	140446300220832 -> 140446300220664
	140446300220832 [label=MkldnnConvolutionBackward0]
	140446300221056 -> 140446300220832
	140446300221056 [label=PreluBackward0]
	140446300221224 -> 140446300221056
	140446300221224 [label=NativeBatchNormBackward0]
	140446300221392 -> 140446300221224
	140446300221392 [label=MkldnnConvolutionBackward0]
	140446300193008 -> 140446300221392
	140446300193008 [label=NativeBatchNormBackward0]
	140446300220720 -> 140446300193008
	140446300220720 [label=AddBackward0]
	140446300193344 -> 140446300220720
	140446300193344 [label=NativeBatchNormBackward0]
	140446300193512 -> 140446300193344
	140446300193512 [label=MkldnnConvolutionBackward0]
	140446300193736 -> 140446300193512
	140446300193736 [label=PreluBackward0]
	140446300193904 -> 140446300193736
	140446300193904 [label=NativeBatchNormBackward0]
	140446300194072 -> 140446300193904
	140446300194072 [label=MkldnnConvolutionBackward0]
	140446300194296 -> 140446300194072
	140446300194296 [label=NativeBatchNormBackward0]
	140446300193400 -> 140446300194296
	140446300193400 [label=AddBackward0]
	140446300194632 -> 140446300193400
	140446300194632 [label=NativeBatchNormBackward0]
	140446300194800 -> 140446300194632
	140446300194800 [label=MkldnnConvolutionBackward0]
	140446300195024 -> 140446300194800
	140446300195024 [label=PreluBackward0]
	140446300195192 -> 140446300195024
	140446300195192 [label=NativeBatchNormBackward0]
	140446300195360 -> 140446300195192
	140446300195360 [label=MkldnnConvolutionBackward0]
	140446300195584 -> 140446300195360
	140446300195584 [label=NativeBatchNormBackward0]
	140446300194688 -> 140446300195584
	140446300194688 [label=AddBackward0]
	140446300195920 -> 140446300194688
	140446300195920 [label=NativeBatchNormBackward0]
	140446300196088 -> 140446300195920
	140446300196088 [label=MkldnnConvolutionBackward0]
	140446300196312 -> 140446300196088
	140446300196312 [label=PreluBackward0]
	140446300196480 -> 140446300196312
	140446300196480 [label=NativeBatchNormBackward0]
	140446300196648 -> 140446300196480
	140446300196648 [label=MkldnnConvolutionBackward0]
	140446300188744 -> 140446300196648
	140446300188744 [label=NativeBatchNormBackward0]
	140446300195976 -> 140446300188744
	140446300195976 [label=AddBackward0]
	140446300189080 -> 140446300195976
	140446300189080 [label=NativeBatchNormBackward0]
	140446300189248 -> 140446300189080
	140446300189248 [label=MkldnnConvolutionBackward0]
	140446300189472 -> 140446300189248
	140446300189472 [label=PreluBackward0]
	140446300189640 -> 140446300189472
	140446300189640 [label=NativeBatchNormBackward0]
	140446300189808 -> 140446300189640
	140446300189808 [label=MkldnnConvolutionBackward0]
	140446300190032 -> 140446300189808
	140446300190032 [label=NativeBatchNormBackward0]
	140446300189136 -> 140446300190032
	140446300189136 [label=AddBackward0]
	140446300190368 -> 140446300189136
	140446300190368 [label=NativeBatchNormBackward0]
	140446300190536 -> 140446300190368
	140446300190536 [label=MkldnnConvolutionBackward0]
	140446300190760 -> 140446300190536
	140446300190760 [label=PreluBackward0]
	140446300190928 -> 140446300190760
	140446300190928 [label=NativeBatchNormBackward0]
	140446300191096 -> 140446300190928
	140446300191096 [label=MkldnnConvolutionBackward0]
	140446300191320 -> 140446300191096
	140446300191320 [label=NativeBatchNormBackward0]
	140446300190424 -> 140446300191320
	140446300190424 [label=AddBackward0]
	140446300191656 -> 140446300190424
	140446300191656 [label=NativeBatchNormBackward0]
	140446300191824 -> 140446300191656
	140446300191824 [label=MkldnnConvolutionBackward0]
	140446300192048 -> 140446300191824
	140446300192048 [label=PreluBackward0]
	140446300192216 -> 140446300192048
	140446300192216 [label=NativeBatchNormBackward0]
	140446300192384 -> 140446300192216
	140446300192384 [label=MkldnnConvolutionBackward0]
	140446300192608 -> 140446300192384
	140446300192608 [label=NativeBatchNormBackward0]
	140446300191712 -> 140446300192608
	140446300191712 [label=AddBackward0]
	140446300152048 -> 140446300191712
	140446300152048 [label=NativeBatchNormBackward0]
	140446300152216 -> 140446300152048
	140446300152216 [label=MkldnnConvolutionBackward0]
	140446300152440 -> 140446300152216
	140446300152440 [label=PreluBackward0]
	140446300152608 -> 140446300152440
	140446300152608 [label=NativeBatchNormBackward0]
	140446300152776 -> 140446300152608
	140446300152776 [label=MkldnnConvolutionBackward0]
	140446300153000 -> 140446300152776
	140446300153000 [label=NativeBatchNormBackward0]
	140446300152104 -> 140446300153000
	140446300152104 [label=AddBackward0]
	140446300153336 -> 140446300152104
	140446300153336 [label=NativeBatchNormBackward0]
	140446300153504 -> 140446300153336
	140446300153504 [label=MkldnnConvolutionBackward0]
	140446300153728 -> 140446300153504
	140446300153728 [label=PreluBackward0]
	140446300153896 -> 140446300153728
	140446300153896 [label=NativeBatchNormBackward0]
	140446300154064 -> 140446300153896
	140446300154064 [label=MkldnnConvolutionBackward0]
	140446300154288 -> 140446300154064
	140446300154288 [label=NativeBatchNormBackward0]
	140446300154456 -> 140446300154288
	140446300154456 [label=AddBackward0]
	140446300154680 -> 140446300154456
	140446300154680 [label=NativeBatchNormBackward0]
	140446300154848 -> 140446300154680
	140446300154848 [label=MkldnnConvolutionBackward0]
	140446300155072 -> 140446300154848
	140446300155072 [label=PreluBackward0]
	140446300155240 -> 140446300155072
	140446300155240 [label=NativeBatchNormBackward0]
	140446300155408 -> 140446300155240
	140446300155408 [label=MkldnnConvolutionBackward0]
	140446300155632 -> 140446300155408
	140446300155632 [label=NativeBatchNormBackward0]
	140446300154736 -> 140446300155632
	140446300154736 [label=AddBackward0]
	140446300041344 -> 140446300154736
	140446300041344 [label=NativeBatchNormBackward0]
	140446300041512 -> 140446300041344
	140446300041512 [label=MkldnnConvolutionBackward0]
	140446300041736 -> 140446300041512
	140446300041736 [label=PreluBackward0]
	140446300041904 -> 140446300041736
	140446300041904 [label=NativeBatchNormBackward0]
	140446300042072 -> 140446300041904
	140446300042072 [label=MkldnnConvolutionBackward0]
	140446300042296 -> 140446300042072
	140446300042296 [label=NativeBatchNormBackward0]
	140446300041400 -> 140446300042296
	140446300041400 [label=AddBackward0]
	140446300042632 -> 140446300041400
	140446300042632 [label=NativeBatchNormBackward0]
	140446300042800 -> 140446300042632
	140446300042800 [label=MkldnnConvolutionBackward0]
	140446300043024 -> 140446300042800
	140446300043024 [label=PreluBackward0]
	140446300043192 -> 140446300043024
	140446300043192 [label=NativeBatchNormBackward0]
	140446300043360 -> 140446300043192
	140446300043360 [label=MkldnnConvolutionBackward0]
	140446300043584 -> 140446300043360
	140446300043584 [label=NativeBatchNormBackward0]
	140446300042688 -> 140446300043584
	140446300042688 [label=AddBackward0]
	140446300043920 -> 140446300042688
	140446300043920 [label=NativeBatchNormBackward0]
	140446300044088 -> 140446300043920
	140446300044088 [label=MkldnnConvolutionBackward0]
	140446300044312 -> 140446300044088
	140446300044312 [label=PreluBackward0]
	140446300044480 -> 140446300044312
	140446300044480 [label=NativeBatchNormBackward0]
	140446300044648 -> 140446300044480
	140446300044648 [label=MkldnnConvolutionBackward0]
	140446300044872 -> 140446300044648
	140446300044872 [label=NativeBatchNormBackward0]
	140446300045040 -> 140446300044872
	140446300045040 [label=AddBackward0]
	140446300045264 -> 140446300045040
	140446300045264 [label=NativeBatchNormBackward0]
	140446300078264 -> 140446300045264
	140446300078264 [label=MkldnnConvolutionBackward0]
	140446300078488 -> 140446300078264
	140446300078488 [label=PreluBackward0]
	140446300078656 -> 140446300078488
	140446300078656 [label=NativeBatchNormBackward0]
	140446300078824 -> 140446300078656
	140446300078824 [label=MkldnnConvolutionBackward0]
	140446300079048 -> 140446300078824
	140446300079048 [label=NativeBatchNormBackward0]
	140446300078152 -> 140446300079048
	140446300078152 [label=AddBackward0]
	140446300079384 -> 140446300078152
	140446300079384 [label=NativeBatchNormBackward0]
	140446300079552 -> 140446300079384
	140446300079552 [label=MkldnnConvolutionBackward0]
	140446300079776 -> 140446300079552
	140446300079776 [label=PreluBackward0]
	140446300079944 -> 140446300079776
	140446300079944 [label=NativeBatchNormBackward0]
	140446300080112 -> 140446300079944
	140446300080112 [label=MkldnnConvolutionBackward0]
	140446300080336 -> 140446300080112
	140446300080336 [label=NativeBatchNormBackward0]
	140446300079440 -> 140446300080336
	140446300079440 [label=AddBackward0]
	140446300080672 -> 140446300079440
	140446300080672 [label=NativeBatchNormBackward0]
	140446300080840 -> 140446300080672
	140446300080840 [label=MkldnnConvolutionBackward0]
	140446300081064 -> 140446300080840
	140446300081064 [label=PreluBackward0]
	140446300081232 -> 140446300081064
	140446300081232 [label=NativeBatchNormBackward0]
	140446300081400 -> 140446300081232
	140446300081400 [label=MkldnnConvolutionBackward0]
	140446300081624 -> 140446300081400
	140446300081624 [label=NativeBatchNormBackward0]
	140446300081792 -> 140446300081624
	140446300081792 [label=PreluBackward0]
	140446300082016 -> 140446300081792
	140446300082016 [label=NativeBatchNormBackward0]
	140446300037192 -> 140446300082016
	140446300037192 [label=MkldnnConvolutionBackward0]
	140446300037416 -> 140446300037192
	140446623308680 [label="
 (50, 3, 112, 112)" fillcolor=lightblue]
	140446623308680 -> 140446300037416
	140446300037416 [label=AccumulateGrad]
	140446300037472 -> 140446300037192
	140446623306760 [label="encoder.arcFace50.conv1.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	140446623306760 -> 140446300037472
	140446300037472 [label=AccumulateGrad]
	140446300037248 -> 140446300082016
	140446623306840 [label="encoder.arcFace50.bn1.weight
 (64)" fillcolor=lightblue]
	140446623306840 -> 140446300037248
	140446300037248 [label=AccumulateGrad]
	140446300037304 -> 140446300082016
	140446623306920 [label="encoder.arcFace50.bn1.bias
 (64)" fillcolor=lightblue]
	140446623306920 -> 140446300037304
	140446300037304 [label=AccumulateGrad]
	140446300082072 -> 140446300081792
	140446623307240 [label="encoder.arcFace50.prelu.weight
 (64)" fillcolor=lightblue]
	140446623307240 -> 140446300082072
	140446300082072 [label=AccumulateGrad]
	140446300081848 -> 140446300081624
	140446623307880 [label="encoder.arcFace50.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	140446623307880 -> 140446300081848
	140446300081848 [label=AccumulateGrad]
	140446300081904 -> 140446300081624
	140446623307960 [label="encoder.arcFace50.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	140446623307960 -> 140446300081904
	140446300081904 [label=AccumulateGrad]
	140446300081680 -> 140446300081400
	140446623308360 [label="encoder.arcFace50.layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140446623308360 -> 140446300081680
	140446300081680 [label=AccumulateGrad]
	140446300081456 -> 140446300081232
	140446623308440 [label="encoder.arcFace50.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	140446623308440 -> 140446300081456
	140446300081456 [label=AccumulateGrad]
	140446300081512 -> 140446300081232
	140446623308520 [label="encoder.arcFace50.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	140446623308520 -> 140446300081512
	140446300081512 [label=AccumulateGrad]
	140446300081288 -> 140446300081064
	140446623308840 [label="encoder.arcFace50.layer1.0.prelu.weight
 (64)" fillcolor=lightblue]
	140446623308840 -> 140446300081288
	140446300081288 [label=AccumulateGrad]
	140446300081120 -> 140446300080840
	140446623309000 [label="encoder.arcFace50.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140446623309000 -> 140446300081120
	140446300081120 [label=AccumulateGrad]
	140446300080896 -> 140446300080672
	140446623309080 [label="encoder.arcFace50.layer1.0.bn3.weight
 (64)" fillcolor=lightblue]
	140446623309080 -> 140446300080896
	140446300080896 [label=AccumulateGrad]
	140446300080952 -> 140446300080672
	140446623309160 [label="encoder.arcFace50.layer1.0.bn3.bias
 (64)" fillcolor=lightblue]
	140446623309160 -> 140446300080952
	140446300080952 [label=AccumulateGrad]
	140446300080728 -> 140446300079440
	140446300080728 [label=NativeBatchNormBackward0]
	140446300081008 -> 140446300080728
	140446300081008 [label=MkldnnConvolutionBackward0]
	140446300081792 -> 140446300081008
	140446300081344 -> 140446300081008
	140446623307400 [label="encoder.arcFace50.layer1.0.downsample.0.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	140446623307400 -> 140446300081344
	140446300081344 [label=AccumulateGrad]
	140446300081176 -> 140446300080728
	140446623307480 [label="encoder.arcFace50.layer1.0.downsample.1.weight
 (64)" fillcolor=lightblue]
	140446623307480 -> 140446300081176
	140446300081176 [label=AccumulateGrad]
	140446300081568 -> 140446300080728
	140446623307560 [label="encoder.arcFace50.layer1.0.downsample.1.bias
 (64)" fillcolor=lightblue]
	140446623307560 -> 140446300081568
	140446300081568 [label=AccumulateGrad]
	140446300080504 -> 140446300080336
	140446623309480 [label="encoder.arcFace50.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	140446623309480 -> 140446300080504
	140446300080504 [label=AccumulateGrad]
	140446300080560 -> 140446300080336
	140446623309560 [label="encoder.arcFace50.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	140446623309560 -> 140446300080560
	140446300080560 [label=AccumulateGrad]
	140446300080392 -> 140446300080112
	140446623367400 [label="encoder.arcFace50.layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140446623367400 -> 140446300080392
	140446300080392 [label=AccumulateGrad]
	140446300080168 -> 140446300079944
	140446623367480 [label="encoder.arcFace50.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	140446623367480 -> 140446300080168
	140446300080168 [label=AccumulateGrad]
	140446300080224 -> 140446300079944
	140446623367560 [label="encoder.arcFace50.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	140446623367560 -> 140446300080224
	140446300080224 [label=AccumulateGrad]
	140446300080000 -> 140446300079776
	140446623367880 [label="encoder.arcFace50.layer1.1.prelu.weight
 (64)" fillcolor=lightblue]
	140446623367880 -> 140446300080000
	140446300080000 [label=AccumulateGrad]
	140446300079832 -> 140446300079552
	140446623368040 [label="encoder.arcFace50.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140446623368040 -> 140446300079832
	140446300079832 [label=AccumulateGrad]
	140446300079608 -> 140446300079384
	140446623368120 [label="encoder.arcFace50.layer1.1.bn3.weight
 (64)" fillcolor=lightblue]
	140446623368120 -> 140446300079608
	140446300079608 [label=AccumulateGrad]
	140446300079664 -> 140446300079384
	140446623368200 [label="encoder.arcFace50.layer1.1.bn3.bias
 (64)" fillcolor=lightblue]
	140446623368200 -> 140446300079664
	140446300079664 [label=AccumulateGrad]
	140446300079440 -> 140446300078152
	140446300079216 -> 140446300079048
	140446623368520 [label="encoder.arcFace50.layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	140446623368520 -> 140446300079216
	140446300079216 [label=AccumulateGrad]
	140446300079272 -> 140446300079048
	140446623368600 [label="encoder.arcFace50.layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	140446623368600 -> 140446300079272
	140446300079272 [label=AccumulateGrad]
	140446300079104 -> 140446300078824
	140446623369000 [label="encoder.arcFace50.layer1.2.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140446623369000 -> 140446300079104
	140446300079104 [label=AccumulateGrad]
	140446300078880 -> 140446300078656
	140446623369080 [label="encoder.arcFace50.layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	140446623369080 -> 140446300078880
	140446300078880 [label=AccumulateGrad]
	140446300078936 -> 140446300078656
	140446623369160 [label="encoder.arcFace50.layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	140446623369160 -> 140446300078936
	140446300078936 [label=AccumulateGrad]
	140446300078712 -> 140446300078488
	140446623369480 [label="encoder.arcFace50.layer1.2.prelu.weight
 (64)" fillcolor=lightblue]
	140446623369480 -> 140446300078712
	140446300078712 [label=AccumulateGrad]
	140446300078544 -> 140446300078264
	140446623369640 [label="encoder.arcFace50.layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140446623369640 -> 140446300078544
	140446300078544 [label=AccumulateGrad]
	140446300078320 -> 140446300045264
	140446623369720 [label="encoder.arcFace50.layer1.2.bn3.weight
 (64)" fillcolor=lightblue]
	140446623369720 -> 140446300078320
	140446300078320 [label=AccumulateGrad]
	140446300078376 -> 140446300045264
	140446623369800 [label="encoder.arcFace50.layer1.2.bn3.bias
 (64)" fillcolor=lightblue]
	140446623369800 -> 140446300078376
	140446300078376 [label=AccumulateGrad]
	140446300078152 -> 140446300045040
	140446300045096 -> 140446300044872
	140446623370680 [label="encoder.arcFace50.layer2.0.bn1.weight
 (64)" fillcolor=lightblue]
	140446623370680 -> 140446300045096
	140446300045096 [label=AccumulateGrad]
	140446300045152 -> 140446300044872
	140446623370760 [label="encoder.arcFace50.layer2.0.bn1.bias
 (64)" fillcolor=lightblue]
	140446623370760 -> 140446300045152
	140446300045152 [label=AccumulateGrad]
	140446300044928 -> 140446300044648
	140446623371160 [label="encoder.arcFace50.layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140446623371160 -> 140446300044928
	140446300044928 [label=AccumulateGrad]
	140446300044704 -> 140446300044480
	140446623432776 [label="encoder.arcFace50.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	140446623432776 -> 140446300044704
	140446300044704 [label=AccumulateGrad]
	140446300044760 -> 140446300044480
	140446623432856 [label="encoder.arcFace50.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	140446623432856 -> 140446300044760
	140446300044760 [label=AccumulateGrad]
	140446300044536 -> 140446300044312
	140446623433176 [label="encoder.arcFace50.layer2.0.prelu.weight
 (128)" fillcolor=lightblue]
	140446623433176 -> 140446300044536
	140446300044536 [label=AccumulateGrad]
	140446300044368 -> 140446300044088
	140446623433336 [label="encoder.arcFace50.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140446623433336 -> 140446300044368
	140446300044368 [label=AccumulateGrad]
	140446300044144 -> 140446300043920
	140446623433416 [label="encoder.arcFace50.layer2.0.bn3.weight
 (128)" fillcolor=lightblue]
	140446623433416 -> 140446300044144
	140446300044144 [label=AccumulateGrad]
	140446300044200 -> 140446300043920
	140446623433496 [label="encoder.arcFace50.layer2.0.bn3.bias
 (128)" fillcolor=lightblue]
	140446623433496 -> 140446300044200
	140446300044200 [label=AccumulateGrad]
	140446300043976 -> 140446300042688
	140446300043976 [label=NativeBatchNormBackward0]
	140446300044256 -> 140446300043976
	140446300044256 [label=MkldnnConvolutionBackward0]
	140446300045040 -> 140446300044256
	140446300044592 -> 140446300044256
	140446623370200 [label="encoder.arcFace50.layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	140446623370200 -> 140446300044592
	140446300044592 [label=AccumulateGrad]
	140446300044424 -> 140446300043976
	140446623370280 [label="encoder.arcFace50.layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	140446623370280 -> 140446300044424
	140446300044424 [label=AccumulateGrad]
	140446300044816 -> 140446300043976
	140446623370360 [label="encoder.arcFace50.layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	140446623370360 -> 140446300044816
	140446300044816 [label=AccumulateGrad]
	140446300043752 -> 140446300043584
	140446623433816 [label="encoder.arcFace50.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	140446623433816 -> 140446300043752
	140446300043752 [label=AccumulateGrad]
	140446300043808 -> 140446300043584
	140446623433896 [label="encoder.arcFace50.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	140446623433896 -> 140446300043808
	140446300043808 [label=AccumulateGrad]
	140446300043640 -> 140446300043360
	140446623434296 [label="encoder.arcFace50.layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140446623434296 -> 140446300043640
	140446300043640 [label=AccumulateGrad]
	140446300043416 -> 140446300043192
	140446623434376 [label="encoder.arcFace50.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	140446623434376 -> 140446300043416
	140446300043416 [label=AccumulateGrad]
	140446300043472 -> 140446300043192
	140446623434456 [label="encoder.arcFace50.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	140446623434456 -> 140446300043472
	140446300043472 [label=AccumulateGrad]
	140446300043248 -> 140446300043024
	140446623434776 [label="encoder.arcFace50.layer2.1.prelu.weight
 (128)" fillcolor=lightblue]
	140446623434776 -> 140446300043248
	140446300043248 [label=AccumulateGrad]
	140446300043080 -> 140446300042800
	140446623434936 [label="encoder.arcFace50.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140446623434936 -> 140446300043080
	140446300043080 [label=AccumulateGrad]
	140446300042856 -> 140446300042632
	140446623435016 [label="encoder.arcFace50.layer2.1.bn3.weight
 (128)" fillcolor=lightblue]
	140446623435016 -> 140446300042856
	140446300042856 [label=AccumulateGrad]
	140446300042912 -> 140446300042632
	140446623435096 [label="encoder.arcFace50.layer2.1.bn3.bias
 (128)" fillcolor=lightblue]
	140446623435096 -> 140446300042912
	140446300042912 [label=AccumulateGrad]
	140446300042688 -> 140446300041400
	140446300042464 -> 140446300042296
	140446623435416 [label="encoder.arcFace50.layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	140446623435416 -> 140446300042464
	140446300042464 [label=AccumulateGrad]
	140446300042520 -> 140446300042296
	140446623435496 [label="encoder.arcFace50.layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	140446623435496 -> 140446300042520
	140446300042520 [label=AccumulateGrad]
	140446300042352 -> 140446300042072
	140446623435896 [label="encoder.arcFace50.layer2.2.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140446623435896 -> 140446300042352
	140446300042352 [label=AccumulateGrad]
	140446300042128 -> 140446300041904
	140446623435976 [label="encoder.arcFace50.layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	140446623435976 -> 140446300042128
	140446300042128 [label=AccumulateGrad]
	140446300042184 -> 140446300041904
	140446623436056 [label="encoder.arcFace50.layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	140446623436056 -> 140446300042184
	140446300042184 [label=AccumulateGrad]
	140446300041960 -> 140446300041736
	140446623436376 [label="encoder.arcFace50.layer2.2.prelu.weight
 (128)" fillcolor=lightblue]
	140446623436376 -> 140446300041960
	140446300041960 [label=AccumulateGrad]
	140446300041792 -> 140446300041512
	140446623436536 [label="encoder.arcFace50.layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140446623436536 -> 140446300041792
	140446300041792 [label=AccumulateGrad]
	140446300041568 -> 140446300041344
	140446623436616 [label="encoder.arcFace50.layer2.2.bn3.weight
 (128)" fillcolor=lightblue]
	140446623436616 -> 140446300041568
	140446300041568 [label=AccumulateGrad]
	140446300041624 -> 140446300041344
	140446623436696 [label="encoder.arcFace50.layer2.2.bn3.bias
 (128)" fillcolor=lightblue]
	140446623436696 -> 140446300041624
	140446300041624 [label=AccumulateGrad]
	140446300041400 -> 140446300154736
	140446300155800 -> 140446300155632
	140446623498552 [label="encoder.arcFace50.layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	140446623498552 -> 140446300155800
	140446300155800 [label=AccumulateGrad]
	140446300155856 -> 140446300155632
	140446623498632 [label="encoder.arcFace50.layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	140446623498632 -> 140446300155856
	140446300155856 [label=AccumulateGrad]
	140446300155688 -> 140446300155408
	140446623499032 [label="encoder.arcFace50.layer2.3.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140446623499032 -> 140446300155688
	140446300155688 [label=AccumulateGrad]
	140446300155464 -> 140446300155240
	140446623499112 [label="encoder.arcFace50.layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	140446623499112 -> 140446300155464
	140446300155464 [label=AccumulateGrad]
	140446300155520 -> 140446300155240
	140446623499192 [label="encoder.arcFace50.layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	140446623499192 -> 140446300155520
	140446300155520 [label=AccumulateGrad]
	140446300155296 -> 140446300155072
	140446623499512 [label="encoder.arcFace50.layer2.3.prelu.weight
 (128)" fillcolor=lightblue]
	140446623499512 -> 140446300155296
	140446300155296 [label=AccumulateGrad]
	140446300155128 -> 140446300154848
	140446623499672 [label="encoder.arcFace50.layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140446623499672 -> 140446300155128
	140446300155128 [label=AccumulateGrad]
	140446300154904 -> 140446300154680
	140446623499752 [label="encoder.arcFace50.layer2.3.bn3.weight
 (128)" fillcolor=lightblue]
	140446623499752 -> 140446300154904
	140446300154904 [label=AccumulateGrad]
	140446300154960 -> 140446300154680
	140446623499832 [label="encoder.arcFace50.layer2.3.bn3.bias
 (128)" fillcolor=lightblue]
	140446623499832 -> 140446300154960
	140446300154960 [label=AccumulateGrad]
	140446300154736 -> 140446300154456
	140446300154512 -> 140446300154288
	140446623500712 [label="encoder.arcFace50.layer3.0.bn1.weight
 (128)" fillcolor=lightblue]
	140446623500712 -> 140446300154512
	140446300154512 [label=AccumulateGrad]
	140446300154568 -> 140446300154288
	140446623500792 [label="encoder.arcFace50.layer3.0.bn1.bias
 (128)" fillcolor=lightblue]
	140446623500792 -> 140446300154568
	140446300154568 [label=AccumulateGrad]
	140446300154344 -> 140446300154064
	140446623501192 [label="encoder.arcFace50.layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	140446623501192 -> 140446300154344
	140446300154344 [label=AccumulateGrad]
	140446300154120 -> 140446300153896
	140446623501272 [label="encoder.arcFace50.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	140446623501272 -> 140446300154120
	140446300154120 [label=AccumulateGrad]
	140446300154176 -> 140446300153896
	140446623501352 [label="encoder.arcFace50.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	140446623501352 -> 140446300154176
	140446300154176 [label=AccumulateGrad]
	140446300153952 -> 140446300153728
	140446623501672 [label="encoder.arcFace50.layer3.0.prelu.weight
 (256)" fillcolor=lightblue]
	140446623501672 -> 140446300153952
	140446300153952 [label=AccumulateGrad]
	140446300153784 -> 140446300153504
	140446623501832 [label="encoder.arcFace50.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623501832 -> 140446300153784
	140446300153784 [label=AccumulateGrad]
	140446300153560 -> 140446300153336
	140446623501912 [label="encoder.arcFace50.layer3.0.bn3.weight
 (256)" fillcolor=lightblue]
	140446623501912 -> 140446300153560
	140446300153560 [label=AccumulateGrad]
	140446300153616 -> 140446300153336
	140446623501992 [label="encoder.arcFace50.layer3.0.bn3.bias
 (256)" fillcolor=lightblue]
	140446623501992 -> 140446300153616
	140446300153616 [label=AccumulateGrad]
	140446300153392 -> 140446300152104
	140446300153392 [label=NativeBatchNormBackward0]
	140446300153672 -> 140446300153392
	140446300153672 [label=MkldnnConvolutionBackward0]
	140446300154456 -> 140446300153672
	140446300154008 -> 140446300153672
	140446623500232 [label="encoder.arcFace50.layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	140446623500232 -> 140446300154008
	140446300154008 [label=AccumulateGrad]
	140446300153840 -> 140446300153392
	140446623500312 [label="encoder.arcFace50.layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	140446623500312 -> 140446300153840
	140446300153840 [label=AccumulateGrad]
	140446300154232 -> 140446300153392
	140446623500392 [label="encoder.arcFace50.layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	140446623500392 -> 140446300154232
	140446300154232 [label=AccumulateGrad]
	140446300153168 -> 140446300153000
	140446623039560 [label="encoder.arcFace50.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	140446623039560 -> 140446300153168
	140446300153168 [label=AccumulateGrad]
	140446300153224 -> 140446300153000
	140446623039640 [label="encoder.arcFace50.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	140446623039640 -> 140446300153224
	140446300153224 [label=AccumulateGrad]
	140446300153056 -> 140446300152776
	140446623040040 [label="encoder.arcFace50.layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623040040 -> 140446300153056
	140446300153056 [label=AccumulateGrad]
	140446300152832 -> 140446300152608
	140446623040120 [label="encoder.arcFace50.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	140446623040120 -> 140446300152832
	140446300152832 [label=AccumulateGrad]
	140446300152888 -> 140446300152608
	140446623040200 [label="encoder.arcFace50.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	140446623040200 -> 140446300152888
	140446300152888 [label=AccumulateGrad]
	140446300152664 -> 140446300152440
	140446623040520 [label="encoder.arcFace50.layer3.1.prelu.weight
 (256)" fillcolor=lightblue]
	140446623040520 -> 140446300152664
	140446300152664 [label=AccumulateGrad]
	140446300152496 -> 140446300152216
	140446623040680 [label="encoder.arcFace50.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623040680 -> 140446300152496
	140446300152496 [label=AccumulateGrad]
	140446300152272 -> 140446300152048
	140446623040760 [label="encoder.arcFace50.layer3.1.bn3.weight
 (256)" fillcolor=lightblue]
	140446623040760 -> 140446300152272
	140446300152272 [label=AccumulateGrad]
	140446300152328 -> 140446300152048
	140446623040840 [label="encoder.arcFace50.layer3.1.bn3.bias
 (256)" fillcolor=lightblue]
	140446623040840 -> 140446300152328
	140446300152328 [label=AccumulateGrad]
	140446300152104 -> 140446300191712
	140446300151880 -> 140446300192608
	140446623041160 [label="encoder.arcFace50.layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	140446623041160 -> 140446300151880
	140446300151880 [label=AccumulateGrad]
	140446300151936 -> 140446300192608
	140446623041240 [label="encoder.arcFace50.layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	140446623041240 -> 140446300151936
	140446300151936 [label=AccumulateGrad]
	140446300192664 -> 140446300192384
	140446623041640 [label="encoder.arcFace50.layer3.2.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623041640 -> 140446300192664
	140446300192664 [label=AccumulateGrad]
	140446300192440 -> 140446300192216
	140446623041720 [label="encoder.arcFace50.layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	140446623041720 -> 140446300192440
	140446300192440 [label=AccumulateGrad]
	140446300192496 -> 140446300192216
	140446623041800 [label="encoder.arcFace50.layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	140446623041800 -> 140446300192496
	140446300192496 [label=AccumulateGrad]
	140446300192272 -> 140446300192048
	140446623042120 [label="encoder.arcFace50.layer3.2.prelu.weight
 (256)" fillcolor=lightblue]
	140446623042120 -> 140446300192272
	140446300192272 [label=AccumulateGrad]
	140446300192104 -> 140446300191824
	140446623042280 [label="encoder.arcFace50.layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623042280 -> 140446300192104
	140446300192104 [label=AccumulateGrad]
	140446300191880 -> 140446300191656
	140446623042360 [label="encoder.arcFace50.layer3.2.bn3.weight
 (256)" fillcolor=lightblue]
	140446623042360 -> 140446300191880
	140446300191880 [label=AccumulateGrad]
	140446300191936 -> 140446300191656
	140446623042440 [label="encoder.arcFace50.layer3.2.bn3.bias
 (256)" fillcolor=lightblue]
	140446623042440 -> 140446300191936
	140446300191936 [label=AccumulateGrad]
	140446300191712 -> 140446300190424
	140446300191488 -> 140446300191320
	140446623042760 [label="encoder.arcFace50.layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	140446623042760 -> 140446300191488
	140446300191488 [label=AccumulateGrad]
	140446300191544 -> 140446300191320
	140446623042840 [label="encoder.arcFace50.layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	140446623042840 -> 140446300191544
	140446300191544 [label=AccumulateGrad]
	140446300191376 -> 140446300191096
	140446623043240 [label="encoder.arcFace50.layer3.3.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623043240 -> 140446300191376
	140446300191376 [label=AccumulateGrad]
	140446300191152 -> 140446300190928
	140446623043320 [label="encoder.arcFace50.layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	140446623043320 -> 140446300191152
	140446300191152 [label=AccumulateGrad]
	140446300191208 -> 140446300190928
	140446623043400 [label="encoder.arcFace50.layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	140446623043400 -> 140446300191208
	140446300191208 [label=AccumulateGrad]
	140446300190984 -> 140446300190760
	140446623101160 [label="encoder.arcFace50.layer3.3.prelu.weight
 (256)" fillcolor=lightblue]
	140446623101160 -> 140446300190984
	140446300190984 [label=AccumulateGrad]
	140446300190816 -> 140446300190536
	140446623101320 [label="encoder.arcFace50.layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623101320 -> 140446300190816
	140446300190816 [label=AccumulateGrad]
	140446300190592 -> 140446300190368
	140446623101400 [label="encoder.arcFace50.layer3.3.bn3.weight
 (256)" fillcolor=lightblue]
	140446623101400 -> 140446300190592
	140446300190592 [label=AccumulateGrad]
	140446300190648 -> 140446300190368
	140446623101480 [label="encoder.arcFace50.layer3.3.bn3.bias
 (256)" fillcolor=lightblue]
	140446623101480 -> 140446300190648
	140446300190648 [label=AccumulateGrad]
	140446300190424 -> 140446300189136
	140446300190200 -> 140446300190032
	140446623101800 [label="encoder.arcFace50.layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	140446623101800 -> 140446300190200
	140446300190200 [label=AccumulateGrad]
	140446300190256 -> 140446300190032
	140446623101880 [label="encoder.arcFace50.layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	140446623101880 -> 140446300190256
	140446300190256 [label=AccumulateGrad]
	140446300190088 -> 140446300189808
	140446623102280 [label="encoder.arcFace50.layer3.4.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623102280 -> 140446300190088
	140446300190088 [label=AccumulateGrad]
	140446300189864 -> 140446300189640
	140446623102360 [label="encoder.arcFace50.layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	140446623102360 -> 140446300189864
	140446300189864 [label=AccumulateGrad]
	140446300189920 -> 140446300189640
	140446623102440 [label="encoder.arcFace50.layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	140446623102440 -> 140446300189920
	140446300189920 [label=AccumulateGrad]
	140446300189696 -> 140446300189472
	140446623102760 [label="encoder.arcFace50.layer3.4.prelu.weight
 (256)" fillcolor=lightblue]
	140446623102760 -> 140446300189696
	140446300189696 [label=AccumulateGrad]
	140446300189528 -> 140446300189248
	140446623102920 [label="encoder.arcFace50.layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623102920 -> 140446300189528
	140446300189528 [label=AccumulateGrad]
	140446300189304 -> 140446300189080
	140446623103000 [label="encoder.arcFace50.layer3.4.bn3.weight
 (256)" fillcolor=lightblue]
	140446623103000 -> 140446300189304
	140446300189304 [label=AccumulateGrad]
	140446300189360 -> 140446300189080
	140446623103080 [label="encoder.arcFace50.layer3.4.bn3.bias
 (256)" fillcolor=lightblue]
	140446623103080 -> 140446300189360
	140446300189360 [label=AccumulateGrad]
	140446300189136 -> 140446300195976
	140446300188912 -> 140446300188744
	140446623103400 [label="encoder.arcFace50.layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	140446623103400 -> 140446300188912
	140446300188912 [label=AccumulateGrad]
	140446300188968 -> 140446300188744
	140446623103480 [label="encoder.arcFace50.layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	140446623103480 -> 140446300188968
	140446300188968 [label=AccumulateGrad]
	140446300188800 -> 140446300196648
	140446623103880 [label="encoder.arcFace50.layer3.5.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623103880 -> 140446300188800
	140446300188800 [label=AccumulateGrad]
	140446300196704 -> 140446300196480
	140446623103960 [label="encoder.arcFace50.layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	140446623103960 -> 140446300196704
	140446300196704 [label=AccumulateGrad]
	140446300196760 -> 140446300196480
	140446623104040 [label="encoder.arcFace50.layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	140446623104040 -> 140446300196760
	140446300196760 [label=AccumulateGrad]
	140446300196536 -> 140446300196312
	140446623104360 [label="encoder.arcFace50.layer3.5.prelu.weight
 (256)" fillcolor=lightblue]
	140446623104360 -> 140446300196536
	140446300196536 [label=AccumulateGrad]
	140446300196368 -> 140446300196088
	140446623104520 [label="encoder.arcFace50.layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623104520 -> 140446300196368
	140446300196368 [label=AccumulateGrad]
	140446300196144 -> 140446300195920
	140446623104600 [label="encoder.arcFace50.layer3.5.bn3.weight
 (256)" fillcolor=lightblue]
	140446623104600 -> 140446300196144
	140446300196144 [label=AccumulateGrad]
	140446300196200 -> 140446300195920
	140446623104680 [label="encoder.arcFace50.layer3.5.bn3.bias
 (256)" fillcolor=lightblue]
	140446623104680 -> 140446300196200
	140446300196200 [label=AccumulateGrad]
	140446300195976 -> 140446300194688
	140446300195752 -> 140446300195584
	140446623174728 [label="encoder.arcFace50.layer3.6.bn1.weight
 (256)" fillcolor=lightblue]
	140446623174728 -> 140446300195752
	140446300195752 [label=AccumulateGrad]
	140446300195808 -> 140446300195584
	140446623174808 [label="encoder.arcFace50.layer3.6.bn1.bias
 (256)" fillcolor=lightblue]
	140446623174808 -> 140446300195808
	140446300195808 [label=AccumulateGrad]
	140446300195640 -> 140446300195360
	140446623175208 [label="encoder.arcFace50.layer3.6.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623175208 -> 140446300195640
	140446300195640 [label=AccumulateGrad]
	140446300195416 -> 140446300195192
	140446623175288 [label="encoder.arcFace50.layer3.6.bn2.weight
 (256)" fillcolor=lightblue]
	140446623175288 -> 140446300195416
	140446300195416 [label=AccumulateGrad]
	140446300195472 -> 140446300195192
	140446623175368 [label="encoder.arcFace50.layer3.6.bn2.bias
 (256)" fillcolor=lightblue]
	140446623175368 -> 140446300195472
	140446300195472 [label=AccumulateGrad]
	140446300195248 -> 140446300195024
	140446623175688 [label="encoder.arcFace50.layer3.6.prelu.weight
 (256)" fillcolor=lightblue]
	140446623175688 -> 140446300195248
	140446300195248 [label=AccumulateGrad]
	140446300195080 -> 140446300194800
	140446623175848 [label="encoder.arcFace50.layer3.6.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623175848 -> 140446300195080
	140446300195080 [label=AccumulateGrad]
	140446300194856 -> 140446300194632
	140446623175928 [label="encoder.arcFace50.layer3.6.bn3.weight
 (256)" fillcolor=lightblue]
	140446623175928 -> 140446300194856
	140446300194856 [label=AccumulateGrad]
	140446300194912 -> 140446300194632
	140446623176008 [label="encoder.arcFace50.layer3.6.bn3.bias
 (256)" fillcolor=lightblue]
	140446623176008 -> 140446300194912
	140446300194912 [label=AccumulateGrad]
	140446300194688 -> 140446300193400
	140446300194464 -> 140446300194296
	140446623176328 [label="encoder.arcFace50.layer3.7.bn1.weight
 (256)" fillcolor=lightblue]
	140446623176328 -> 140446300194464
	140446300194464 [label=AccumulateGrad]
	140446300194520 -> 140446300194296
	140446623176408 [label="encoder.arcFace50.layer3.7.bn1.bias
 (256)" fillcolor=lightblue]
	140446623176408 -> 140446300194520
	140446300194520 [label=AccumulateGrad]
	140446300194352 -> 140446300194072
	140446623176808 [label="encoder.arcFace50.layer3.7.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623176808 -> 140446300194352
	140446300194352 [label=AccumulateGrad]
	140446300194128 -> 140446300193904
	140446623176888 [label="encoder.arcFace50.layer3.7.bn2.weight
 (256)" fillcolor=lightblue]
	140446623176888 -> 140446300194128
	140446300194128 [label=AccumulateGrad]
	140446300194184 -> 140446300193904
	140446623176968 [label="encoder.arcFace50.layer3.7.bn2.bias
 (256)" fillcolor=lightblue]
	140446623176968 -> 140446300194184
	140446300194184 [label=AccumulateGrad]
	140446300193960 -> 140446300193736
	140446623177288 [label="encoder.arcFace50.layer3.7.prelu.weight
 (256)" fillcolor=lightblue]
	140446623177288 -> 140446300193960
	140446300193960 [label=AccumulateGrad]
	140446300193792 -> 140446300193512
	140446623177448 [label="encoder.arcFace50.layer3.7.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623177448 -> 140446300193792
	140446300193792 [label=AccumulateGrad]
	140446300193568 -> 140446300193344
	140446623177528 [label="encoder.arcFace50.layer3.7.bn3.weight
 (256)" fillcolor=lightblue]
	140446623177528 -> 140446300193568
	140446300193568 [label=AccumulateGrad]
	140446300193624 -> 140446300193344
	140446623177608 [label="encoder.arcFace50.layer3.7.bn3.bias
 (256)" fillcolor=lightblue]
	140446623177608 -> 140446300193624
	140446300193624 [label=AccumulateGrad]
	140446300193400 -> 140446300220720
	140446300193176 -> 140446300193008
	140446623177928 [label="encoder.arcFace50.layer3.8.bn1.weight
 (256)" fillcolor=lightblue]
	140446623177928 -> 140446300193176
	140446300193176 [label=AccumulateGrad]
	140446300193232 -> 140446300193008
	140446623178008 [label="encoder.arcFace50.layer3.8.bn1.bias
 (256)" fillcolor=lightblue]
	140446623178008 -> 140446300193232
	140446300193232 [label=AccumulateGrad]
	140446300193064 -> 140446300221392
	140446623178408 [label="encoder.arcFace50.layer3.8.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623178408 -> 140446300193064
	140446300193064 [label=AccumulateGrad]
	140446300192840 -> 140446300221224
	140446623178488 [label="encoder.arcFace50.layer3.8.bn2.weight
 (256)" fillcolor=lightblue]
	140446623178488 -> 140446300192840
	140446300192840 [label=AccumulateGrad]
	140446300192896 -> 140446300221224
	140446623178568 [label="encoder.arcFace50.layer3.8.bn2.bias
 (256)" fillcolor=lightblue]
	140446623178568 -> 140446300192896
	140446300192896 [label=AccumulateGrad]
	140446300221280 -> 140446300221056
	140446623228136 [label="encoder.arcFace50.layer3.8.prelu.weight
 (256)" fillcolor=lightblue]
	140446623228136 -> 140446300221280
	140446300221280 [label=AccumulateGrad]
	140446300221112 -> 140446300220832
	140446623228296 [label="encoder.arcFace50.layer3.8.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623228296 -> 140446300221112
	140446300221112 [label=AccumulateGrad]
	140446300220888 -> 140446300220664
	140446623228376 [label="encoder.arcFace50.layer3.8.bn3.weight
 (256)" fillcolor=lightblue]
	140446623228376 -> 140446300220888
	140446300220888 [label=AccumulateGrad]
	140446300220944 -> 140446300220664
	140446623228456 [label="encoder.arcFace50.layer3.8.bn3.bias
 (256)" fillcolor=lightblue]
	140446623228456 -> 140446300220944
	140446300220944 [label=AccumulateGrad]
	140446300220720 -> 140446300219432
	140446300220496 -> 140446300220328
	140446623228776 [label="encoder.arcFace50.layer3.9.bn1.weight
 (256)" fillcolor=lightblue]
	140446623228776 -> 140446300220496
	140446300220496 [label=AccumulateGrad]
	140446300220552 -> 140446300220328
	140446623228856 [label="encoder.arcFace50.layer3.9.bn1.bias
 (256)" fillcolor=lightblue]
	140446623228856 -> 140446300220552
	140446300220552 [label=AccumulateGrad]
	140446300220384 -> 140446300220104
	140446623229256 [label="encoder.arcFace50.layer3.9.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623229256 -> 140446300220384
	140446300220384 [label=AccumulateGrad]
	140446300220160 -> 140446300219936
	140446623229336 [label="encoder.arcFace50.layer3.9.bn2.weight
 (256)" fillcolor=lightblue]
	140446623229336 -> 140446300220160
	140446300220160 [label=AccumulateGrad]
	140446300220216 -> 140446300219936
	140446623229416 [label="encoder.arcFace50.layer3.9.bn2.bias
 (256)" fillcolor=lightblue]
	140446623229416 -> 140446300220216
	140446300220216 [label=AccumulateGrad]
	140446300219992 -> 140446300219768
	140446623229736 [label="encoder.arcFace50.layer3.9.prelu.weight
 (256)" fillcolor=lightblue]
	140446623229736 -> 140446300219992
	140446300219992 [label=AccumulateGrad]
	140446300219824 -> 140446300219544
	140446623229896 [label="encoder.arcFace50.layer3.9.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623229896 -> 140446300219824
	140446300219824 [label=AccumulateGrad]
	140446300219600 -> 140446300219376
	140446623229976 [label="encoder.arcFace50.layer3.9.bn3.weight
 (256)" fillcolor=lightblue]
	140446623229976 -> 140446300219600
	140446300219600 [label=AccumulateGrad]
	140446300219656 -> 140446300219376
	140446623230056 [label="encoder.arcFace50.layer3.9.bn3.bias
 (256)" fillcolor=lightblue]
	140446623230056 -> 140446300219656
	140446300219656 [label=AccumulateGrad]
	140446300219432 -> 140446300218144
	140446300219208 -> 140446300219040
	140446623230376 [label="encoder.arcFace50.layer3.10.bn1.weight
 (256)" fillcolor=lightblue]
	140446623230376 -> 140446300219208
	140446300219208 [label=AccumulateGrad]
	140446300219264 -> 140446300219040
	140446623230456 [label="encoder.arcFace50.layer3.10.bn1.bias
 (256)" fillcolor=lightblue]
	140446623230456 -> 140446300219264
	140446300219264 [label=AccumulateGrad]
	140446300219096 -> 140446300218816
	140446623230856 [label="encoder.arcFace50.layer3.10.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623230856 -> 140446300219096
	140446300219096 [label=AccumulateGrad]
	140446300218872 -> 140446300218648
	140446623230936 [label="encoder.arcFace50.layer3.10.bn2.weight
 (256)" fillcolor=lightblue]
	140446623230936 -> 140446300218872
	140446300218872 [label=AccumulateGrad]
	140446300218928 -> 140446300218648
	140446623231016 [label="encoder.arcFace50.layer3.10.bn2.bias
 (256)" fillcolor=lightblue]
	140446623231016 -> 140446300218928
	140446300218928 [label=AccumulateGrad]
	140446300218704 -> 140446300218480
	140446623231336 [label="encoder.arcFace50.layer3.10.prelu.weight
 (256)" fillcolor=lightblue]
	140446623231336 -> 140446300218704
	140446300218704 [label=AccumulateGrad]
	140446300218536 -> 140446300218256
	140446623231496 [label="encoder.arcFace50.layer3.10.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446623231496 -> 140446300218536
	140446300218536 [label=AccumulateGrad]
	140446300218312 -> 140446300218088
	140446623231576 [label="encoder.arcFace50.layer3.10.bn3.weight
 (256)" fillcolor=lightblue]
	140446623231576 -> 140446300218312
	140446300218312 [label=AccumulateGrad]
	140446300218368 -> 140446300218088
	140446623231656 [label="encoder.arcFace50.layer3.10.bn3.bias
 (256)" fillcolor=lightblue]
	140446623231656 -> 140446300218368
	140446300218368 [label=AccumulateGrad]
	140446300218144 -> 140446300216792
	140446300217920 -> 140446300217752
	140446581416008 [label="encoder.arcFace50.layer3.11.bn1.weight
 (256)" fillcolor=lightblue]
	140446581416008 -> 140446300217920
	140446300217920 [label=AccumulateGrad]
	140446300217976 -> 140446300217752
	140446581416088 [label="encoder.arcFace50.layer3.11.bn1.bias
 (256)" fillcolor=lightblue]
	140446581416088 -> 140446300217976
	140446300217976 [label=AccumulateGrad]
	140446300217808 -> 140446300217528
	140446581416488 [label="encoder.arcFace50.layer3.11.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446581416488 -> 140446300217808
	140446300217808 [label=AccumulateGrad]
	140446300217584 -> 140446300217296
	140446581416568 [label="encoder.arcFace50.layer3.11.bn2.weight
 (256)" fillcolor=lightblue]
	140446581416568 -> 140446300217584
	140446300217584 [label=AccumulateGrad]
	140446300217640 -> 140446300217296
	140446581416648 [label="encoder.arcFace50.layer3.11.bn2.bias
 (256)" fillcolor=lightblue]
	140446581416648 -> 140446300217640
	140446300217640 [label=AccumulateGrad]
	140446300217416 -> 140446300217128
	140446581416968 [label="encoder.arcFace50.layer3.11.prelu.weight
 (256)" fillcolor=lightblue]
	140446581416968 -> 140446300217416
	140446300217416 [label=AccumulateGrad]
	140446300217184 -> 140446300216904
	140446581417128 [label="encoder.arcFace50.layer3.11.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446581417128 -> 140446300217184
	140446300217184 [label=AccumulateGrad]
	140446300216960 -> 140446300216736
	140446581417208 [label="encoder.arcFace50.layer3.11.bn3.weight
 (256)" fillcolor=lightblue]
	140446581417208 -> 140446300216960
	140446300216960 [label=AccumulateGrad]
	140446300217016 -> 140446300216736
	140446581417288 [label="encoder.arcFace50.layer3.11.bn3.bias
 (256)" fillcolor=lightblue]
	140446581417288 -> 140446300217016
	140446300217016 [label=AccumulateGrad]
	140446300216792 -> 140446300215504
	140446300216568 -> 140446300216400
	140446581417608 [label="encoder.arcFace50.layer3.12.bn1.weight
 (256)" fillcolor=lightblue]
	140446581417608 -> 140446300216568
	140446300216568 [label=AccumulateGrad]
	140446300216624 -> 140446300216400
	140446581417688 [label="encoder.arcFace50.layer3.12.bn1.bias
 (256)" fillcolor=lightblue]
	140446581417688 -> 140446300216624
	140446300216624 [label=AccumulateGrad]
	140446300216456 -> 140446300216176
	140446581418088 [label="encoder.arcFace50.layer3.12.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446581418088 -> 140446300216456
	140446300216456 [label=AccumulateGrad]
	140446300216232 -> 140446300216008
	140446581418168 [label="encoder.arcFace50.layer3.12.bn2.weight
 (256)" fillcolor=lightblue]
	140446581418168 -> 140446300216232
	140446300216232 [label=AccumulateGrad]
	140446300216288 -> 140446300216008
	140446581418248 [label="encoder.arcFace50.layer3.12.bn2.bias
 (256)" fillcolor=lightblue]
	140446581418248 -> 140446300216288
	140446300216288 [label=AccumulateGrad]
	140446300216064 -> 140446300215840
	140446581418568 [label="encoder.arcFace50.layer3.12.prelu.weight
 (256)" fillcolor=lightblue]
	140446581418568 -> 140446300216064
	140446300216064 [label=AccumulateGrad]
	140446300215896 -> 140446300215616
	140446581418728 [label="encoder.arcFace50.layer3.12.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446581418728 -> 140446300215896
	140446300215896 [label=AccumulateGrad]
	140446300215672 -> 140446300215448
	140446581418808 [label="encoder.arcFace50.layer3.12.bn3.weight
 (256)" fillcolor=lightblue]
	140446581418808 -> 140446300215672
	140446300215672 [label=AccumulateGrad]
	140446300215728 -> 140446300215448
	140446581418888 [label="encoder.arcFace50.layer3.12.bn3.bias
 (256)" fillcolor=lightblue]
	140446581418888 -> 140446300215728
	140446300215728 [label=AccumulateGrad]
	140446300215504 -> 140446300214216
	140446300215280 -> 140446300215112
	140446581419208 [label="encoder.arcFace50.layer3.13.bn1.weight
 (256)" fillcolor=lightblue]
	140446581419208 -> 140446300215280
	140446300215280 [label=AccumulateGrad]
	140446300215336 -> 140446300215112
	140446581419288 [label="encoder.arcFace50.layer3.13.bn1.bias
 (256)" fillcolor=lightblue]
	140446581419288 -> 140446300215336
	140446300215336 [label=AccumulateGrad]
	140446300215168 -> 140446300214888
	140446581419688 [label="encoder.arcFace50.layer3.13.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446581419688 -> 140446300215168
	140446300215168 [label=AccumulateGrad]
	140446300214944 -> 140446300214720
	140446581419768 [label="encoder.arcFace50.layer3.13.bn2.weight
 (256)" fillcolor=lightblue]
	140446581419768 -> 140446300214944
	140446300214944 [label=AccumulateGrad]
	140446300215000 -> 140446300214720
	140446581419848 [label="encoder.arcFace50.layer3.13.bn2.bias
 (256)" fillcolor=lightblue]
	140446581419848 -> 140446300215000
	140446300215000 [label=AccumulateGrad]
	140446300214776 -> 140446300214552
	140446581473512 [label="encoder.arcFace50.layer3.13.prelu.weight
 (256)" fillcolor=lightblue]
	140446581473512 -> 140446300214776
	140446300214776 [label=AccumulateGrad]
	140446300214608 -> 140446300214328
	140446581473672 [label="encoder.arcFace50.layer3.13.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140446581473672 -> 140446300214608
	140446300214608 [label=AccumulateGrad]
	140446300214384 -> 140446300214160
	140446581473752 [label="encoder.arcFace50.layer3.13.bn3.weight
 (256)" fillcolor=lightblue]
	140446581473752 -> 140446300214384
	140446300214384 [label=AccumulateGrad]
	140446300214440 -> 140446300214160
	140446581473832 [label="encoder.arcFace50.layer3.13.bn3.bias
 (256)" fillcolor=lightblue]
	140446581473832 -> 140446300214440
	140446300214440 [label=AccumulateGrad]
	140446300214216 -> 140446300213936
	140446300213992 -> 140446300213768
	140446581474712 [label="encoder.arcFace50.layer4.0.bn1.weight
 (256)" fillcolor=lightblue]
	140446581474712 -> 140446300213992
	140446300213992 [label=AccumulateGrad]
	140446300214048 -> 140446300213768
	140446581474792 [label="encoder.arcFace50.layer4.0.bn1.bias
 (256)" fillcolor=lightblue]
	140446581474792 -> 140446300214048
	140446300214048 [label=AccumulateGrad]
	140446300213824 -> 140446300213544
	140446581475192 [label="encoder.arcFace50.layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	140446581475192 -> 140446300213824
	140446300213824 [label=AccumulateGrad]
	140446300213600 -> 140446300213376
	140446581475272 [label="encoder.arcFace50.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	140446581475272 -> 140446300213600
	140446300213600 [label=AccumulateGrad]
	140446300213656 -> 140446300213376
	140446581475352 [label="encoder.arcFace50.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	140446581475352 -> 140446300213656
	140446300213656 [label=AccumulateGrad]
	140446300213432 -> 140446300125112
	140446581475672 [label="encoder.arcFace50.layer4.0.prelu.weight
 (512)" fillcolor=lightblue]
	140446581475672 -> 140446300213432
	140446300213432 [label=AccumulateGrad]
	140446300126568 -> 140446300124944
	140446581475832 [label="encoder.arcFace50.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140446581475832 -> 140446300126568
	140446300126568 [label=AccumulateGrad]
	140446300125000 -> 140446300124776
	140446581475912 [label="encoder.arcFace50.layer4.0.bn3.weight
 (512)" fillcolor=lightblue]
	140446581475912 -> 140446300125000
	140446300125000 [label=AccumulateGrad]
	140446300125056 -> 140446300124776
	140446581475992 [label="encoder.arcFace50.layer4.0.bn3.bias
 (512)" fillcolor=lightblue]
	140446581475992 -> 140446300125056
	140446300125056 [label=AccumulateGrad]
	140446300124832 -> 140446300123544
	140446300124832 [label=NativeBatchNormBackward0]
	140446300125504 -> 140446300124832
	140446300125504 [label=MkldnnConvolutionBackward0]
	140446300213936 -> 140446300125504
	140446300213488 -> 140446300125504
	140446581474232 [label="encoder.arcFace50.layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140446581474232 -> 140446300213488
	140446300213488 [label=AccumulateGrad]
	140446300213320 -> 140446300124832
	140446581474312 [label="encoder.arcFace50.layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	140446581474312 -> 140446300213320
	140446300213320 [label=AccumulateGrad]
	140446300213712 -> 140446300124832
	140446581474392 [label="encoder.arcFace50.layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	140446581474392 -> 140446300213712
	140446300213712 [label=AccumulateGrad]
	140446300124608 -> 140446300124440
	140446581476312 [label="encoder.arcFace50.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	140446581476312 -> 140446300124608
	140446300124608 [label=AccumulateGrad]
	140446300124664 -> 140446300124440
	140446581476392 [label="encoder.arcFace50.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	140446581476392 -> 140446300124664
	140446300124664 [label=AccumulateGrad]
	140446300124496 -> 140446300124216
	140446581476792 [label="encoder.arcFace50.layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140446581476792 -> 140446300124496
	140446300124496 [label=AccumulateGrad]
	140446300124272 -> 140446300124048
	140446581476872 [label="encoder.arcFace50.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	140446581476872 -> 140446300124272
	140446300124272 [label=AccumulateGrad]
	140446300124328 -> 140446300124048
	140446581476952 [label="encoder.arcFace50.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	140446581476952 -> 140446300124328
	140446300124328 [label=AccumulateGrad]
	140446300124104 -> 140446300123880
	140446581477272 [label="encoder.arcFace50.layer4.1.prelu.weight
 (512)" fillcolor=lightblue]
	140446581477272 -> 140446300124104
	140446300124104 [label=AccumulateGrad]
	140446300123936 -> 140446300123656
	140446581543064 [label="encoder.arcFace50.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140446581543064 -> 140446300123936
	140446300123936 [label=AccumulateGrad]
	140446300123712 -> 140446300123488
	140446581543144 [label="encoder.arcFace50.layer4.1.bn3.weight
 (512)" fillcolor=lightblue]
	140446581543144 -> 140446300123712
	140446300123712 [label=AccumulateGrad]
	140446300123768 -> 140446300123488
	140446581543224 [label="encoder.arcFace50.layer4.1.bn3.bias
 (512)" fillcolor=lightblue]
	140446581543224 -> 140446300123768
	140446300123768 [label=AccumulateGrad]
	140446300123544 -> 140446300126400
	140446300123320 -> 140446300125280
	140446581543544 [label="encoder.arcFace50.layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	140446581543544 -> 140446300123320
	140446300123320 [label=AccumulateGrad]
	140446300123376 -> 140446300125280
	140446581543624 [label="encoder.arcFace50.layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	140446581543624 -> 140446300123376
	140446300123376 [label=AccumulateGrad]
	140446300123208 -> 140446300125560
	140446581544024 [label="encoder.arcFace50.layer4.2.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140446581544024 -> 140446300123208
	140446300123208 [label=AccumulateGrad]
	140446300125336 -> 140446300125784
	140446581544104 [label="encoder.arcFace50.layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	140446581544104 -> 140446300125336
	140446300125336 [label=AccumulateGrad]
	140446300125448 -> 140446300125784
	140446581544184 [label="encoder.arcFace50.layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	140446581544184 -> 140446300125448
	140446300125448 [label=AccumulateGrad]
	140446300125672 -> 140446300126008
	140446581544504 [label="encoder.arcFace50.layer4.2.prelu.weight
 (512)" fillcolor=lightblue]
	140446581544504 -> 140446300125672
	140446300125672 [label=AccumulateGrad]
	140446300125952 -> 140446300126232
	140446581544664 [label="encoder.arcFace50.layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140446581544664 -> 140446300125952
	140446300125952 [label=AccumulateGrad]
	140446300126176 -> 140446300126456
	140446581544744 [label="encoder.arcFace50.layer4.2.bn3.weight
 (512)" fillcolor=lightblue]
	140446581544744 -> 140446300126176
	140446300126176 [label=AccumulateGrad]
	140446300125896 -> 140446300126456
	140446581544824 [label="encoder.arcFace50.layer4.2.bn3.bias
 (512)" fillcolor=lightblue]
	140446581544824 -> 140446300125896
	140446300125896 [label=AccumulateGrad]
	140446300126400 -> 140446300126736
	140446300126680 -> 140446300126624
	140446581545144 [label="encoder.arcFace50.bn2.weight
 (512)" fillcolor=lightblue]
	140446581545144 -> 140446300126680
	140446300126680 [label=AccumulateGrad]
	140446300126344 -> 140446300126624
	140446581545224 [label="encoder.arcFace50.bn2.bias
 (512)" fillcolor=lightblue]
	140446581545224 -> 140446300126344
	140446300126344 [label=AccumulateGrad]
	140446300126904 -> 140446300127072
	140446300126904 [label=TBackward0]
	140446300126792 -> 140446300126904
	140446581545544 [label="encoder.arcFace50.fc.weight
 (2048, 25088)" fillcolor=lightblue]
	140446581545544 -> 140446300126792
	140446300126792 [label=AccumulateGrad]
	140446300127184 -> 140446581489616
	140446581545784 [label="encoder.arcFace50.features.bias
 (2048)" fillcolor=lightblue]
	140446581545784 -> 140446300127184
	140446300127184 [label=AccumulateGrad]
	140446581489280 -> 140446581489224
	140446581489280 [label=TBackward0]
	140446581489448 -> 140446581489280
	140446581546104 [label="C_gender.linear.weight
 (4, 512)" fillcolor=lightblue]
	140446581546104 -> 140446581489448
	140446581489448 [label=AccumulateGrad]
	140446581489224 -> 140446258330504
	140446258330584 [label="
 (50, 4)" fillcolor=darkolivegreen1]
	140446581489560 [label=AddmmBackward0]
	140446581489112 -> 140446581489560
	140446581546344 [label="C_age.linear.bias
 (4)" fillcolor=lightblue]
	140446581546344 -> 140446581489112
	140446581489112 [label=AccumulateGrad]
	140446581488608 -> 140446581489560
	140446581488608 [label=SliceBackward0]
	140446300126512 -> 140446581488608
	140446300126512 [label=SliceBackward0]
	140446581489504 -> 140446300126512
	140446300127128 -> 140446581489560
	140446300127128 [label=TBackward0]
	140446300126064 -> 140446300127128
	140446581546264 [label="C_age.linear.weight
 (4, 512)" fillcolor=lightblue]
	140446581546264 -> 140446300126064
	140446300126064 [label=AccumulateGrad]
	140446581489560 -> 140446258330584
	140446258330984 [label="
 (50, 4)" fillcolor=darkolivegreen1]
	140446300125840 [label=AddmmBackward0]
	140446300126848 -> 140446300125840
	140446581546504 [label="C_race.linear.bias
 (4)" fillcolor=lightblue]
	140446581546504 -> 140446300126848
	140446300126848 [label=AccumulateGrad]
	140446300125224 -> 140446300125840
	140446300125224 [label=SliceBackward0]
	140446300125616 -> 140446300125224
	140446300125616 [label=SliceBackward0]
	140446581489504 -> 140446300125616
	140446300126288 -> 140446300125840
	140446300126288 [label=TBackward0]
	140446300123600 -> 140446300126288
	140446581546424 [label="C_race.linear.weight
 (4, 512)" fillcolor=lightblue]
	140446581546424 -> 140446300123600
	140446300123600 [label=AccumulateGrad]
	140446300125840 -> 140446258330984
	140446258331384 [label="
 (50, 4)" fillcolor=darkolivegreen1]
	140446300123824 [label=AddmmBackward0]
	140446300123264 -> 140446300123824
	140446581546664 [label="C_id.linear.bias
 (4)" fillcolor=lightblue]
	140446581546664 -> 140446300123264
	140446300123264 [label=AccumulateGrad]
	140446300123992 -> 140446300123824
	140446300123992 [label=SliceBackward0]
	140446300124552 -> 140446300123992
	140446300124552 [label=SliceBackward0]
	140446581489504 -> 140446300124552
	140446300123432 -> 140446300123824
	140446300123432 [label=TBackward0]
	140446300124160 -> 140446300123432
	140446581546584 [label="C_id.linear.weight
 (4, 512)" fillcolor=lightblue]
	140446581546584 -> 140446300124160
	140446300124160 [label=AccumulateGrad]
	140446300123824 -> 140446258331384
	140446581474552 [label="
 (50, 1)" fillcolor=darkolivegreen1]
	140446300124888 [label=AddmmBackward0]
	140446300124384 -> 140446300124888
	140446581546824 [label="C_distr.linear.bias
 (1)" fillcolor=lightblue]
	140446581546824 -> 140446300124384
	140446300124384 [label=AccumulateGrad]
	140446300124720 -> 140446300124888
	140446300124720 [label=CloneBackward0]
	140446581489504 -> 140446300124720
	140446300213880 -> 140446300124888
	140446300213880 [label=TBackward0]
	140446300214104 -> 140446300213880
	140446581546744 [label="C_distr.linear.weight
 (1, 2048)" fillcolor=lightblue]
	140446581546744 -> 140446300214104
	140446300214104 [label=AccumulateGrad]
	140446300124888 -> 140446581474552
	140446581473352 [label="
 (50, 1)" fillcolor=darkolivegreen1]
	140446300214664 [label=AddmmBackward0]
	140446300124384 -> 140446300214664
	140446300214272 -> 140446300214664
	140446300214272 [label=CopySlices]
	140446300215224 -> 140446300214272
	140446300215224 [label=CopySlices]
	140446300215784 -> 140446300215224
	140446300215784 [label=CopySlices]
	140446300216344 -> 140446300215784
	140446300216344 [label=CopySlices]
	140446300216848 -> 140446300216344
	140446300216848 [label=CloneBackward0]
	140446581489504 -> 140446300216848
	140446300217072 -> 140446300216344
	140446300217072 [label=SliceBackward0]
	140446300217240 -> 140446300217072
	140446300217240 [label=SliceBackward0]
	140446300216848 -> 140446300217240
	140446300216512 -> 140446300215784
	140446300216512 [label=AsStridedBackward0]
	140446300216344 -> 140446300216512
	140446300215392 -> 140446300215224
	140446300215392 [label=AsStridedBackward0]
	140446300215784 -> 140446300215392
	140446300214832 -> 140446300214272
	140446300214832 [label=AsStridedBackward0]
	140446300215224 -> 140446300214832
	140446300214496 -> 140446300214664
	140446300214496 [label=TBackward0]
	140446300214104 -> 140446300214496
	140446300214664 -> 140446581473352
}
